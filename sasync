#!/usr/bin/env bash
JSON_FOLDER=/opt/sa                         # Location of folder with service account .json files. No trailing slash
EXCLUDES=/opt/sasync/exclude.txt            # Location of exclude.txt file with list of file types to exclude
MIN_JSON=1; MAX_JSON=1200                   # Set MIN and MAX json file numbers assuming file format is 1.json, 2.json

rclone_remote_check () {
  rclone lsd $1;  if [ $? != 0 ];  then  echo;echo THE REMOTE $1 FAILED. PLEASE CHECK set.* file and rclone.conf;echo;  exit;  fi
}

sacalc () {
  echo;echo CHECKING SIZE of $source and $destination... BE PATIENT, LARGE REMOTES TAKE MINUTES;echo;
  let sourcesize=`rclone size $source --fast-list | sed -e"s/(//" | grep -i "Bytes" | cut -f5 -d " "`+1
  let destsize=`rclone size $destination --fast-list | sed -e"s/(//" | grep -i "Bytes" | cut -f5 -d " "`+1
  let srcdestdiff=$(( $sourcesize<=$destsize?1:$sourcesize - $destsize ))
  let maxtransfer00=$( echo $maxtransfer | cut -d "G" -f1 | echo -e "$(cat -)000000000" )
  let SAs=$(( $srcdestdiff / ( $maxtransfer00 + 1 ) + 1 ))
  echo SOURCE $source size is $(( $sourcesize / 1000000000 ))Gb
  echo DESTINATION $destination size is $(( $destsize / 1000000000 ))GB
  echo DIFFERENCE of $(( $srcdestdiff / 1000000000 ))GB requires $SAs SAs with maxtransfer of $maxtransfer
}
set_rclone_flags () {
  sync=(`echo ${syncsets[$set]}`); echo Line $(( $set + 1 )) of your set is:; echo ${syncsets[$set]};
  if [ ${#sync[@]} -lt 4 ]; then echo Check your "set" file ERRORS; exit; fi
  synccopymove="${sync[0]}"; echo;echo SYNCCOPYMOVE = $synccopymove;
  source="${sync[1]}"; echo SOURCE = $source; rclone_remote_check $source
  destination="${sync[2]}"; echo DESTINATION = $destination; rclone_remote_check $destination
  maxtransfer="${sync[3]}"; echo MAX TRANSFER = $maxtransfer;
  rcloneflags=`echo ${sync[@]} | cut -f 5- -d ' '`; echo rclone flags = $rcloneflags;
  sacalc
  # SAs=1        # If you want to set number of SAs manually then hash out sacalc and unhash this line
}

get_json_count () {
  read COUNT < /opt/sasync/json.count
  if [[ "$COUNT" -gt "$MAX_JSON" ]];
  then let COUNT=$MIN_JSON; fi
  echo $(($COUNT+1)) > /opt/sasync/json.count
}

run_rclone_with_flags () {
  if [ "$sourcesize" == "$destsize" ]; then
    echo Size of source $sourcesize equals size of destination $destsize. Skipping to next source-destination pair.; sleep 2s
  else
    get_json_count
    echo; echo Starting $synccopymove of $source to $destination w $COUNT/$MAX_JSON.json from $input_files; echo
    #timeout 30m\
    rclone $synccopymove $source $destination\
    --drive-server-side-across-configs\
    --max-transfer $maxtransfer\
    --fast-list --size-only -vP --stats 5s\
    --tpslimit 4 --tpslimit-burst 20 --max-backlog 1000000\
    --exclude-from $EXCLUDES --stats-file-name-length 0 $rcloneflags\
    --drive-service-account-file $JSON_FOLDER/$COUNT.json
    echo;echo FINISHED $synccopymove from $source to $destination wJSON $COUNT.json;echo
  fi
}

clean_tds () {
  echo; echo STARTING DEDUPE of identical files from $destination; echo
  rclone dedupe skip $destination -v --drive-use-trash=false --no-traverse --transfers=40
  echo; echo REMOVING EMPTY DIRECTORIES from $destination; echo
  rclone rmdirs $destination -v --drive-use-trash=false --fast-list --transfers=40
  #echo; echo PERMANENTLY DELETING TRASH from $destination; echo
  #rclone delete $destination -v --drive-trashed-only --drive-use-trash=false --fast-list --transfers=40
  #echo; echo STARTING DEDUPE of identical files from $source; rclone dedupe skip $source -v --drive-use-trash=false --no-traverse --transfers=40
  #echo; echo REMOVING EMPTY DIRECTORIES from source; rclone rmdirs $source -v --drive-use-trash=false --fast-list --transfers=40
  #echo; echo PERMANENTLY DELETING TRASH from source; rclone delete $source -v --drive-trashed-only --drive-use-trash=false --fast-list --transfers=40
}

process_all_sets_and_SAs () {
  for set in $(seq 0 $(( $number_of_sync_sets-1 ))); do
    set_rclone_flags
    for SA in $(seq 1 $SAs); do
      run_rclone_with_flags
    done
    clean_tds
  done
}

main () {
  for input_files in $*; do
      readarray syncsets < <( sed '/^#/d' $input_files )
      number_of_sync_sets=$(( ${#syncsets[@]} )); echo Processing $number_of_sync_sets sync sets;echo;
      process_all_sets_and_SAs
  done
}

main $@
