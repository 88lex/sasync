#!/usr/bin/env bash
JSON_FOLDER=/opt/sa                         # Location of folder with service account .json files. No trailing slash
EXCLUDES=/opt/sasync/exclude.txt            # Location of exclude.txt file with list of file types to exclude
MIN_JSON=1; MAX_JSON=1200                   # Set MIN and MAX json file numbers assuming file format is 1.json, 2.json

sacalc () {
  echo;echo Calculating size of $source and $destination;echo;echo WAIT, TAKES A COUPLE SECONDS/MINUTES;echo;
  let sourcesize=`rclone size $source --fast-list | sed -e"s/(//" | grep -i "Bytes" | cut -f5 -d " "`+1
  let destsize=`rclone size $destination --fast-list | sed -e"s/(//" | grep -i "Bytes" | cut -f5 -d " "`+1
  let srcdestdiff=$(( $sourcesize<=$destsize?1:$sourcesize - $destsize ))
  let maxtransfer00=$( echo $maxtransfer | cut -d "G" -f1 | echo -e "$(cat -)000000000" )
  let SAs=$(( $srcdestdiff / ( $maxtransfer00 + 1 ) + 1 ))
  echo Source $source size is $(( $sourcesize / 1000000000 ))GB, Destination $destination size is $(( $destsize / 1000000000 ))GB
  echo Difference of $(( $srcdestdiff / 1000000000 ))GB requires $SAs SAs with maxtransfer of $maxtransfer; sleep 4s
}

set_rclone_flags () {
  sync=(`echo ${syncsets[$set]}`); echo Line $(( $set + 1 )) of your set is:; echo ${syncsets[$set]};
  if [ ${#sync[@]} -lt 8 ]; then echo Check your "set" file ERRORS; exit; fi
  synccopymove="${sync[0]}"; echo;echo SYNCCOPYMOVE = $synccopymove;
  source="${sync[1]}"; echo SOURCE = $source;
  destination="${sync[2]}"; echo DESTINATION = $destination;
  transfers="${sync[3]}"; echo TRANSFERS = $transfers;
  checkers="${sync[4]}"; echo CHECKERS = $checkers;
  chunks="${sync[5]}"; echo DRIVE CHUNK SIZE = $chunks;
  maxtransfer="${sync[7]}"; echo MAX TRANSFER = $maxtransfer;
  rcloneextraflags=`echo ${sync[@]} | cut -f 9- -d ' '`; echo Additional rclone flags are $rcloneextraflags;
  sacalc
  # SAs="${sync[6]}"
}

get_json_count () {
  read COUNT < json.count
  if [[ "$COUNT" -gt "$MAX_JSON" ]];
  then let COUNT=$MIN_JSON; fi
  echo $(($COUNT+1)) > json.count
}

run_rclone_with_flags () {
  if [ "$sourcesize" == "$destsize" ]; then
    echo Size of source $sourcesize equals size of destination $destsize. Skipping to next source-destination pair.; sleep 2s
  else
    get_json_count
    echo; echo Starting $synccopymove of $source to $destination w $COUNT/$MAX_JSON.json from $input_files; echo
    #timeout 30m\
echo    rclone $synccopymove $source $destination\
    --drive-use-trash=false\
    --transfers $transfers --checkers $checkers\
    --max-transfer $maxtransfer --drive-chunk-size $chunks\
    --fast-list --size-only -vP --stats 5s --delete-during\
    --tpslimit 5 --tpslimit-burst 50 --max-backlog 1000000\
    --exclude-from $EXCLUDES --stats-file-name-length 0 $rcloneextraflags\
    --drive-service-account-file $JSON_FOLDER/$COUNT.json
    echo;echo FINISHED $synccopymove from $source to $destination wJSON $COUNT.json;echo
  fi
}

clean_tds () {
  echo; echo STARTING DEDUPE of identical files from $destination; echo
  rclone dedupe skip $destination -v --drive-use-trash=false --no-traverse --transfers=40
  echo; echo REMOVING EMPTY DIRECTORIES from $destination; echo
  rclone rmdirs $destination -v --drive-use-trash=false --fast-list --transfers=40
  echo; echo PERMANENTLY DELETING TRASH from $destination; echo
  rclone delete $destination -v --drive-trashed-only --drive-use-trash=false --fast-list --transfers=40
  #echo; echo STARTING DEDUPE of identical files from $source; rclone dedupe skip $source -v --drive-use-trash=false --no-traverse --transfers=40
  #echo; echo REMOVING EMPTY DIRECTORIES from source; rclone rmdirs $source -v --drive-use-trash=false --fast-list --transfers=40
  #echo; echo PERMANENTLY DELETING TRASH from source; rclone delete $source -v --drive-trashed-only --drive-use-trash=false --fast-list --transfers=40
}

process_all_sets_and_SAs () {
  for set in $(seq 0 $(( $number_of_sync_sets-1 ))); do
    set_rclone_flags
    for SA in $(seq 1 $SAs); do
      run_rclone_with_flags
    done
#    clean_tds
  done
}

main () {
  for input_files in $*; do
      readarray syncsets < <( sed '/^#/d' $input_files )
      number_of_sync_sets=$(( ${#syncsets[@]} ))
      process_all_sets_and_SAs
  done
}

main $@
